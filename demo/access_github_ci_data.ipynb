{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb38a535-2bcd-46eb-8308-74dee0b62b4a",
   "metadata": {},
   "source": [
    "# Collect data for GitHub Action checks/workflow runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7bfd4-0946-4237-93a7-897686ca6a4e",
   "metadata": {},
   "source": [
    "In this notebook, we collect historical test data like the test duration values from running workflows on Github using the GitHub API.\n",
    "\n",
    "From historical test workflow runs, we want to extract:\n",
    "\n",
    "- time durations\n",
    "- workflow run status & conclusion\n",
    "\n",
    "We can get workflow IDs of the test that we are interested in from https://api.github.com/repos/{ORG}/{REPO}/actions/workflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fb7a56-46e8-44c3-a6a0-b4bfe23fe80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef72ba9-5c4a-450d-b866-2e2b739cca6d",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154cd635-e042-434b-9180-f9408e095497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_numbers(test_id):\n",
    "    \"\"\"\n",
    "    Get the total count of tests.\n",
    "    Find the pages on github-actions.\n",
    "    \"\"\"\n",
    "    command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?\"\"\".format(TOKEN, ORG, REPO, test_id)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "    total_count = output['total_count']\n",
    "    page_numbers = int(total_count/30) # by default number of tests on one page is 30\n",
    "    return page_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b74535-4200-49a7-a589-b7adba1bbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workflow_runs(test_id, page_numbers):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    for p in range(1,page_numbers+1):\n",
    "        command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?page={}\"\"\".format(TOKEN, ORG, REPO, test_id, p)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        if p==1:\n",
    "            df = pd.json_normalize(output['workflow_runs'])\n",
    "        else:\n",
    "            df2 = pd.json_normalize(output['workflow_runs'])\n",
    "            df = pd.concat([df, df2], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea54ffd7-9dc3-4331-8f5c-62a3f419130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_check_runs(commits):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    appended_data = []\n",
    "    for commit in commits:\n",
    "        command = \"\"\"curl -L \\\n",
    "          -H \"Accept: application/vnd.github+json\" \\\n",
    "          -H \"Authorization: Bearer {}\"\\\n",
    "          -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "          https://api.github.com/repos/{}/{}/commits/{}/check-runs\"\"\".format(TOKEN, ORG, REPO, commit)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        appended_data.append(pd.json_normalize(output['check_runs']))\n",
    "\n",
    "    df = pd.concat(appended_data, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe31317-ea6b-450c-b818-b0e323d4a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits():\n",
    "    \"This function gets all commit refs for a github repo\"\n",
    "\n",
    "    command =  \"\"\"curl -L \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/commits\"\"\".format(TOKEN, ORG, REPO)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "\n",
    "    df = pd.json_normalize(output)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac6b46-1fc6-41f5-8cdb-cd64bc5a0496",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "We will be fetching the GitHub Action workflows and checks for the repo: https://www.github.com/github/codeql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b754e6-e4ab-4fac-972c-d31289f178f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "TOKEN = os.getenv(\"GITHUB_ACCESS_TOKEN\")\n",
    "ORG = os.getenv(\"ORG\")\n",
    "REPO = os.getenv(\"REPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842fbe80-3d54-4dfb-83c3-c18c5cdcda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode can be \"check or \"workflow\" depending on whether you want to collect checks data or workflows data\n",
    "MODE = \"workflow\"\n",
    "test_id = \"14909022\" # \"CodeQL tests\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7eb146-b77a-4f3e-be81-906a9cf92885",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Workflows: For example, lets collect data for the workflow ID 14909022 for the workflow runs in the repository `github/codeql` https://api.github.com/repos/github/codeql/actions/workflows\n",
    "\n",
    "* Checks: Get commits for a repo and get check runs for each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b21b5a1-60fd-4fd5-9065-dc0bc128b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"check\":\n",
    "    # get checks\n",
    "    df_commits = get_commits()\n",
    "    commit_ids = list(df_commits['sha'])\n",
    "    checks_df = get_check_runs(commit_ids)\n",
    "    test_df = checks_df[['started_at', 'completed_at', 'id', 'status', 'conclusion', 'external_id', 'name']]\n",
    "    test_df = test_df.rename(columns={'external_id': 'test_id', 'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['completed_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['started_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "\n",
    "elif MODE == \"workflow\":\n",
    "    # get workflows\n",
    "    page_numbers = get_page_numbers(test_id)\n",
    "    workflow_df = get_workflow_runs(test_id, page_numbers)\n",
    "    test_df = workflow_df[['created_at', 'updated_at', 'id', 'status', 'conclusion']]\n",
    "    test_df = test_df.rename(columns={'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['updated_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "    test_df['test_id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a3a9d1-d34c-49b1-ae7e-5498281af3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>run_id</th>\n",
       "      <th>status</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-06T10:10:02Z</td>\n",
       "      <td>2023-06-06T10:10:16Z</td>\n",
       "      <td>5187296010</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-06T08:56:19Z</td>\n",
       "      <td>2023-06-06T08:56:40Z</td>\n",
       "      <td>5186591599</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-05T17:07:18Z</td>\n",
       "      <td>2023-06-05T17:07:31Z</td>\n",
       "      <td>5179907330</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-05T08:59:42Z</td>\n",
       "      <td>2023-06-05T08:59:57Z</td>\n",
       "      <td>5175246940</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-02T13:58:51Z</td>\n",
       "      <td>2023-06-02T13:59:04Z</td>\n",
       "      <td>5156289485</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-06-02T10:52:07Z</td>\n",
       "      <td>2023-06-02T10:52:22Z</td>\n",
       "      <td>5154706775</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-06-02T10:51:14Z</td>\n",
       "      <td>2023-06-02T10:51:28Z</td>\n",
       "      <td>5154700372</td>\n",
       "      <td>completed</td>\n",
       "      <td>failure</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-06-01T22:06:34Z</td>\n",
       "      <td>2023-06-01T22:06:48Z</td>\n",
       "      <td>5149673307</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-06-01T15:25:54Z</td>\n",
       "      <td>2023-06-01T15:26:10Z</td>\n",
       "      <td>5146241506</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-05-31T16:05:40Z</td>\n",
       "      <td>2023-05-31T16:05:57Z</td>\n",
       "      <td>5135136494</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at            updated_at      run_id     status  \\\n",
       "0  2023-06-06T10:10:02Z  2023-06-06T10:10:16Z  5187296010  completed   \n",
       "1  2023-06-06T08:56:19Z  2023-06-06T08:56:40Z  5186591599  completed   \n",
       "2  2023-06-05T17:07:18Z  2023-06-05T17:07:31Z  5179907330  completed   \n",
       "3  2023-06-05T08:59:42Z  2023-06-05T08:59:57Z  5175246940  completed   \n",
       "4  2023-06-02T13:58:51Z  2023-06-02T13:59:04Z  5156289485  completed   \n",
       "5  2023-06-02T10:52:07Z  2023-06-02T10:52:22Z  5154706775  completed   \n",
       "6  2023-06-02T10:51:14Z  2023-06-02T10:51:28Z  5154700372  completed   \n",
       "7  2023-06-01T22:06:34Z  2023-06-01T22:06:48Z  5149673307  completed   \n",
       "8  2023-06-01T15:25:54Z  2023-06-01T15:26:10Z  5146241506  completed   \n",
       "9  2023-05-31T16:05:40Z  2023-05-31T16:05:57Z  5135136494  completed   \n",
       "\n",
       "  conclusion  run_duration   test_id  \n",
       "0    success          14.0  14909022  \n",
       "1    success          21.0  14909022  \n",
       "2    success          13.0  14909022  \n",
       "3    success          15.0  14909022  \n",
       "4    success          13.0  14909022  \n",
       "5    success          15.0  14909022  \n",
       "6    failure          14.0  14909022  \n",
       "7    success          14.0  14909022  \n",
       "8    success          16.0  14909022  \n",
       "9    success          17.0  14909022  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b190635-42b8-4011-a244-7dc951375f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "392e9f16-92f5-4ef0-99af-0399765db21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating passing and failing dfs which are neccesary for computing fit distributions\n",
    "passing_df = test_df[test_df['conclusion'] == 'success'] \n",
    "failures_df = test_df[test_df['conclusion'] == 'failure'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9193e440-27a8-4c6f-8a24-23f07e6a2445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12038cd-03aa-44b6-aa8b-e94ec2184d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failures_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb5a164-1b39-4c73-b7e1-b324338c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "passing_train, passing_test = train_test_split(passing_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47a29a24-0031-4b6b-9df9-a14d42eeb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "failing_train, failing_test = train_test_split(failures_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8249748-1e5e-4022-8e40-8c7860b943d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1ade87d-091f-4c5d-99c8-62b8490794ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d94578-0e8c-4ce0-8cb5-4b87c9da6152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a375d6-6271-48db-a532-519665fad2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11973eff-ca6d-4749-bbfe-ebe17d3b3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_train.to_csv(\"../data/processed/{}passing_train.csv\".format(test_id))\n",
    "failing_train.to_csv(\"../data/processed/{}failing_train.csv\".format(test_id))\n",
    "passing_test.to_csv(\"../data/processed/{}passing_test.csv\".format(test_id))\n",
    "failing_test.to_csv(\"../data/processed/{}failing_test.csv\".format(test_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eb1d9-abae-4ab9-b470-0f908ef66c57",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we interact with the github api to collect the data for all workflow runs. In future work, we will look into using this data to perform statistical tests using OSP model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
